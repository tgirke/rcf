---
layout: page
title: News and announcements
---

Note: for the most current information on exceptions on HPCC's cluster please
consult its [Alerts](http://hpcc.ucr.edu/alerts.html) or
[Twitter](https://twitter.com/UCR_HPCC) pages.

## News

### 20 Dec 2018

* All systems are currently down due to a failure of the AC units. Electricians and AC
  technicians are currently on site to fix the problem. We will keep you
  posted on the status.

### Jun 2017

* Charles Forsyth joins HPCC as new full-time HPC systems administrator. - Welcome Chuck!

### Feb 2017

With funding provided by Michael Pazzani's office (RED) we were able to purchase and install major hardware upgrades. This included the following hardware resources:

* Added 28 Intel nodes with a total of 896 CPU cores (or 1,792 logical CPU cores) and 512 GB of RAM per node
* Added 8 NVIDIA K80 GPUs increasing total number of cuda cores in GPU queue to 59,904
* Redesign of Infiniband network to support new computer nodes and enhance future scalabilty of IB network to over 1000 nodes

### Dec 2016

* UCR approval of plans to form HPC Center 

### Sept 2016

* Expansion of GPFS storage system: 2 disk enclosures for 120 8TB drives
* Expansion of high-memory queue: 4 nodes
* Install of new Intel batch queue: 12 nodes

### Mar 2016

* Expansion of batch queues: 14 nodes

### Apr 2015 

* Deployment of new FDR IB network @ 56Gbs
* Deployment of 28 AMD nodes (2,048 AMD cores), funded by NSF-MRI-2014
* Deployment of high-memory Intel nodes (each with 1TB RAM)
* Deployment of GPU nodes (NVIDIA K80)
* Deployment of big data GPFS disk storage system, funded by NIH-S10-2014

### May 2014

Award of equipment grants from NSF and NIH

* NIH-S10-2014 (1S10OD016290-01A1): $652,816
* NSF-MRI-2014 (MRI-1429826): $783,537





